<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/G128.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/G32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/G16.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"njughr.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="阅读方法知乎问题：如何有针对地高效地阅读一篇学术论文？ 要点总结 不要追求完美，没必要逐行读懂，关键是数量要上去，量变引起质变，而不是纠结于一句两句的意思。 带着问题读论文，目的是找到答案为止。先有个大概的、粗略的问题，随着阅读的深入，慢慢提出更细致的问题，进行更深入的阅读。一定是一整批一起读懂到某个层次，而不是逐篇逐篇地整篇一次读懂。这篇博客就是保证一批论文全部至少读到abstract看懂的层次">
<meta property="og:type" content="article">
<meta property="og:title" content="Pipes">
<meta property="og:url" content="https://njughr.github.io/2021/10/29/papers/index.html">
<meta property="og:site_name" content="GHR&#39;s Blog">
<meta property="og:description" content="阅读方法知乎问题：如何有针对地高效地阅读一篇学术论文？ 要点总结 不要追求完美，没必要逐行读懂，关键是数量要上去，量变引起质变，而不是纠结于一句两句的意思。 带着问题读论文，目的是找到答案为止。先有个大概的、粗略的问题，随着阅读的深入，慢慢提出更细致的问题，进行更深入的阅读。一定是一整批一起读懂到某个层次，而不是逐篇逐篇地整篇一次读懂。这篇博客就是保证一批论文全部至少读到abstract看懂的层次">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://njughr.github.io/2021/10/29/papers/1.png">
<meta property="og:image" content="https://njughr.github.io/2021/10/29/papers/qiufen.jpg">
<meta property="article:published_time" content="2021-10-29T11:35:57.000Z">
<meta property="article:modified_time" content="2021-11-08T10:42:14.534Z">
<meta property="article:author" content="Haoran Geng">
<meta property="article:tag" content="ic">
<meta property="article:tag" content="cs">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://njughr.github.io/2021/10/29/papers/1.png">

<link rel="canonical" href="https://njughr.github.io/2021/10/29/papers/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Pipes | GHR's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">GHR's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Yesterday is done. Tomorrow never comes. Today is here.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">23</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">3</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">18</span></a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://njughr.github.io/2021/10/29/papers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/paperboat.jpg">
      <meta itemprop="name" content="Haoran Geng">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="GHR's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Pipes
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-10-29 19:35:57" itemprop="dateCreated datePublished" datetime="2021-10-29T19:35:57+08:00">2021-10-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-11-08 18:42:14" itemprop="dateModified" datetime="2021-11-08T18:42:14+08:00">2021-11-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="阅读方法"><a href="#阅读方法" class="headerlink" title="阅读方法"></a>阅读方法</h1><p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/23924014">知乎问题：如何有针对地高效地阅读一篇学术论文？</a></p>
<h2 id="要点总结"><a href="#要点总结" class="headerlink" title="要点总结"></a>要点总结</h2><hr>
<p>不要追求完美，没必要逐行读懂，关键是数量要上去，量变引起质变，而不是纠结于一句两句的意思。</p>
<p>带着问题读论文，目的是找到答案为止。先有个大概的、粗略的问题，随着阅读的深入，慢慢提出更细致的问题，进行更深入的阅读。<strong>一定是一整批一起读懂到某个层次，而不是逐篇逐篇地整篇一次读懂。</strong>这篇博客就是保证一批论文全部至少读到abstract看懂的层次。</p>
<p><strong>不要读不会用到的东西，白费的力气必须被极小化！其实，绝大部分论文都只需要了解它的主要观念</strong>（这往往比较容易），<strong>而不需要了解它的详细推导过程</strong>（这反而比较费时）。</p>
<p><strong>整批读略过一次之后，就可以规划出一个你以为比较容易懂的阅读次序。想读懂A论文，不一定非得读A论文，或许阅读引用A论文的B论文，可以看看其他人的理解</strong>。</p>
<blockquote>
<p><strong>我读论文远比学生快，分析远比学生深入，主要的是我敢想象与猜测，而且多年训练下来想象与猜测的准确度很高。所以，许多论文我根本不是「读懂」的，而是「猜对」了！</strong>猜错了就猜错了，继续读论文可以容易的知道对错。</p>
</blockquote>
<hr>
<p>批判性地阅读（下面是我自己的大略翻译，原文见<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/23924014/answer/26470331">如何有针对地高效地阅读一篇学术论文？ - Clei的回答 - 知乎 </a>）</p>
<p>分析和评估，而不是简单的总结。看完论文后，不可以只知道“作者说了什么？“，而是要回答”作者如何实现的？“”作者为什么要这样做？”“效果好不好？”，并不一定非得批评，但是一定要有批判的态度。</p>
<p>【下面这些问题比较烦，其实就是What Why How】</p>
  <span id="more"></span>
<p>问自己：</p>
<ul>
<li>作者的主要观点是？</li>
<li>作者的意图是？</li>
<li>作者的目标读者是？</li>
<li>作者用了哪些论据去证明自己的观点？</li>
<li>作者用了哪些实验去证明了自己的论据？</li>
<li>作者的基本假设是？</li>
<li>作者有什么偏见？</li>
</ul>
<p>以上问题的回答需要进行记录。</p>
<p>他还给了很多其他问题，但是个人觉得没有必要看。</p>
<hr>
<p>下面是H.B.Zhou老师课堂上的一些观点：</p>
<ul>
<li>问题是什么，写的什么，主题什么；问题的难点在哪里，必须做的点在哪里；怎么去做的，效果如何。为什么要做，创新点在哪里，打算怎么做，怎么去做的，挑战在哪里。</li>
<li>Scenario：把应用场景画出来，画出来就是：为什么要这么做。</li>
<li>Motivation：动机是什么：难，有挑战，别人没做过；我们有创新；我们有新的解决方案。</li>
<li>Solutions：如何去解决。粗略或者详细的solutions。</li>
<li>任何事情都要有<strong>What Why How</strong>的闭环。讨论问题，应该事事有回响，事事有反馈，要有ACK，总结和跟进。</li>
</ul>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a target="_blank" rel="noopener" href="https://wenku.baidu.com/view/bb3dfb7f31b765ce05081437.html">彭明辉，硕士班研究所新生手册</a></li>
<li>Rosen, Leonard J. and Laurence Behrens, eds. The Allyn &amp; Bacon Handbook. 1994.</li>
<li>栾浩 樊凯 项阳，《科研有方— 做科研和写论文的一些经验》</li>
</ol>
<hr>
<h1 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h1><h2 id="Published-in"><a href="#Published-in" class="headerlink" title="Published in"></a>Published in</h2><h2 id="Title"><a href="#Title" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors"><a href="#Authors" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms"><a href="#Keywords-Index-Terms" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments"><a href="#Comments" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-1"><a href="#References-1" class="headerlink" title="References"></a>References</h2><hr>
<h1 id="Paper27"><a href="#Paper27" class="headerlink" title="Paper27"></a>Paper27</h1><h2 id="Published-in-1"><a href="#Published-in-1" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Madhubabu Anumukonda, Prasadraju Lakkamraju, Shubhajit Roy Chowdhury, “FPGA-Based High-Performance Phonocardiography System for Extraction of Cardiac Sound Components Using Inverse Delayed Neuron Model”, <em>Frontiers in Medical Technology</em>, vol. 3, 2021.</p>
<h2 id="Title-1"><a href="#Title-1" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-1"><a href="#Authors-1" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-1"><a href="#Abstract-1" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-1"><a href="#Keywords-Index-Terms-1" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-1"><a href="#Comments-1" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-2"><a href="#References-2" class="headerlink" title="References"></a>References</h2><h1 id="Paper26"><a href="#Paper26" class="headerlink" title="Paper26"></a>Paper26</h1><h2 id="Published-in-2"><a href="#Published-in-2" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Samba Raju Chiluveru, Manoj Tripathy, Bibhudutta, “Non‐linear activation function approximation using a REMEZ algorithm”, <em>IET Circuits, Devices &amp; Systems</em>, 2021.</p>
<h2 id="Title-2"><a href="#Title-2" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-2"><a href="#Authors-2" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-2"><a href="#Abstract-2" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-2"><a href="#Keywords-Index-Terms-2" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-2"><a href="#Comments-2" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-3"><a href="#References-3" class="headerlink" title="References"></a>References</h2><h1 id="Paper25"><a href="#Paper25" class="headerlink" title="Paper25"></a>Paper25</h1><h2 id="Published-in-3"><a href="#Published-in-3" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Samba Raju Chiluveru, Manoj Tripathy, Snehit Chunarkar, “A Controlled Accuracy-Based Recursive Algorithm for Approximation of Sigmoid Activation”, <em>National Academy Science Letters</em>, 2021.</p>
<h2 id="Title-3"><a href="#Title-3" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-3"><a href="#Authors-3" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-3"><a href="#Abstract-3" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-3"><a href="#Keywords-Index-Terms-3" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-3"><a href="#Comments-3" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-4"><a href="#References-4" class="headerlink" title="References"></a>References</h2><h1 id="Paper24-1110"><a href="#Paper24-1110" class="headerlink" title="Paper24-1110"></a>Paper24-1110</h1><h2 id="Published-in-4"><a href="#Published-in-4" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Hui Chen, Lin Jiang, Heping Yang, Zhonghai Lu, Yuxiang Fu, Li Li, Zongguang Yu, “An Efficient Hardware Architecture with Adjustable Precision and Extensible Range to Implement Sigmoid and Tanh Functions”, <em>Electronics</em>, vol. 9, pp. 1739, 2020.</p>
<h2 id="Title-4"><a href="#Title-4" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-4"><a href="#Authors-4" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-4"><a href="#Abstract-4" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-4"><a href="#Keywords-Index-Terms-4" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-4"><a href="#Comments-4" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-5"><a href="#References-5" class="headerlink" title="References"></a>References</h2><h1 id="Paper23"><a href="#Paper23" class="headerlink" title="Paper23"></a>Paper23</h1><h2 id="Published-in-5"><a href="#Published-in-5" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Yunqi Gao, Feng Luan, Jiaqi Pan, Xu Li, Yaodong He, “FPGA-Based Implementation of Stochastic Configuration Networks for Regression Prediction”, <em>Sensors</em>, vol. 20, pp. 4191, 2020.</p>
<h2 id="Title-5"><a href="#Title-5" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-5"><a href="#Authors-5" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-5"><a href="#Abstract-5" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-5"><a href="#Keywords-Index-Terms-5" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-5"><a href="#Comments-5" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-6"><a href="#References-6" class="headerlink" title="References"></a>References</h2><h1 id="Paper22"><a href="#Paper22" class="headerlink" title="Paper22"></a>Paper22</h1><h2 id="Published-in-6"><a href="#Published-in-6" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>S.R. Chiluveru, M. Tripathy, B. Mohapatra, “Accuracy controlled iterative method for efficient sigmoid function approximation”, <em>Electronics Letters</em>, 2020.</p>
<h2 id="Title-6"><a href="#Title-6" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-6"><a href="#Authors-6" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-6"><a href="#Abstract-6" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-6"><a href="#Keywords-Index-Terms-6" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-6"><a href="#Comments-6" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-7"><a href="#References-7" class="headerlink" title="References"></a>References</h2><h1 id="Paper21"><a href="#Paper21" class="headerlink" title="Paper21"></a>Paper21</h1><h2 id="Published-in-7"><a href="#Published-in-7" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Linyu Wei, Jueping Cai, Vantruong Nguyen, Jie Chu, Kailin Wen, “P-SFA: Probability based Sigmoid Function Approximation for Low-complexity Hardware Implementation”, <em>Microprocessors and Microsystems</em>, pp. 103105, 2020.</p>
<h2 id="Title-7"><a href="#Title-7" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-7"><a href="#Authors-7" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-7"><a href="#Abstract-7" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-7"><a href="#Keywords-Index-Terms-7" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-7"><a href="#Comments-7" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-8"><a href="#References-8" class="headerlink" title="References"></a>References</h2><h1 id="Paper20"><a href="#Paper20" class="headerlink" title="Paper20"></a>Paper20</h1><h2 id="Published-in-8"><a href="#Published-in-8" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Xuhui Yang, Qingguo Zhou, Jinqiang Wang, Lihong Han, Fang Feng, Rui Zhou, Kuan-Ching Li, “FPGA-based approximate calculation system of General Vector Machine”, <em>Microelectronics Journal</em>, 2019.</p>
<h2 id="Title-8"><a href="#Title-8" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-8"><a href="#Authors-8" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-8"><a href="#Abstract-8" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-8"><a href="#Keywords-Index-Terms-8" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-8"><a href="#Comments-8" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-9"><a href="#References-9" class="headerlink" title="References"></a>References</h2><h1 id="Paper19"><a href="#Paper19" class="headerlink" title="Paper19"></a>Paper19</h1><h2 id="Published-in-9"><a href="#Published-in-9" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Samba Raju Chiluveru, Gyanendra, Snehit Chunarkar, Manoj Tripathy, Brajesh Kumar Kaushik, “Efficient Hardware Implementation of DNN-Based Speech Enhancement Algorithm With Precise Sigmoid Activation Function”, <em>Circuits and Systems II: Express Briefs IEEE Transactions on</em>, vol. 68, no. 11, pp. 3461-3465, 2021.</p>
<h2 id="Title-9"><a href="#Title-9" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-9"><a href="#Authors-9" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-9"><a href="#Abstract-9" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-9"><a href="#Keywords-Index-Terms-9" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-9"><a href="#Comments-9" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-10"><a href="#References-10" class="headerlink" title="References"></a>References</h2><h1 id="Paper18"><a href="#Paper18" class="headerlink" title="Paper18"></a>Paper18</h1><h2 id="Published-in-10"><a href="#Published-in-10" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Fatemeh Mohammadi Shakiba, MengChu Zhou, “Novel Analog Implementation of a Hyperbolic Tangent Neuron in Artificial Neural Networks”, <em>Industrial Electronics IEEE Transactions on</em>, vol. 68, no. 11, pp. 10856-10867, 2021.</p>
<h2 id="Title-10"><a href="#Title-10" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-10"><a href="#Authors-10" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-10"><a href="#Abstract-10" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-10"><a href="#Keywords-Index-Terms-10" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-10"><a href="#Comments-10" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-11"><a href="#References-11" class="headerlink" title="References"></a>References</h2><h1 id="Paper17"><a href="#Paper17" class="headerlink" title="Paper17"></a>Paper17</h1><h2 id="Published-in-11"><a href="#Published-in-11" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Muhammad Awais Hussain, Tsung-Han Tsai, “An Efficient and Fast Softmax Hardware Architecture (EFSHA) for Deep Neural Networks”, <em>Artificial Intelligence Circuits and Systems (AICAS) 2021 IEEE 3rd International Conference on</em>, pp. 1-4, 2021.</p>
<h2 id="Title-11"><a href="#Title-11" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-11"><a href="#Authors-11" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-11"><a href="#Abstract-11" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-11"><a href="#Keywords-Index-Terms-11" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-11"><a href="#Comments-11" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-12"><a href="#References-12" class="headerlink" title="References"></a>References</h2><h1 id="Paper16"><a href="#Paper16" class="headerlink" title="Paper16"></a>Paper16</h1><h2 id="Published-in-12"><a href="#Published-in-12" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Mahmoud Masadeh, Osman Hasan, Sofiène Tahar, “Machine-Learning-Based Self-Tunable Design of Approximate Computing”, <em>Very Large Scale Integration (VLSI) Systems IEEE Transactions on</em>, vol. 29, no. 4, pp. 800-813, 2021.</p>
<h2 id="Title-12"><a href="#Title-12" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-12"><a href="#Authors-12" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-12"><a href="#Abstract-12" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-12"><a href="#Keywords-Index-Terms-12" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-12"><a href="#Comments-12" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-13"><a href="#References-13" class="headerlink" title="References"></a>References</h2><h1 id="Paper15"><a href="#Paper15" class="headerlink" title="Paper15"></a>Paper15</h1><h2 id="Published-in-13"><a href="#Published-in-13" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Wen-Chang Yang, Shu-Yun Lin, Tsung-Chu Huang, “Range-Lookup Approximate Computing Acceleration for Any Activation Functions in Low-Power Neural Network”, <em>Consumer Electronics - Taiwan (ICCE-Taiwan) 2020 IEEE International Conference on</em>, pp. 1-2, 2020.</p>
<h2 id="Title-13"><a href="#Title-13" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-13"><a href="#Authors-13" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-13"><a href="#Abstract-13" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-13"><a href="#Keywords-Index-Terms-13" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-13"><a href="#Comments-13" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-14"><a href="#References-14" class="headerlink" title="References"></a>References</h2><h1 id="Paper14"><a href="#Paper14" class="headerlink" title="Paper14"></a>Paper14</h1><h2 id="Published-in-14"><a href="#Published-in-14" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Hui Chen, Lin Jiang, Yuanyong Luo, Zhonghai Lu, Yuxiang Fu, Li Li, Zongguang Yu, “A CORDIC-Based Architecture with Adjustable Precision and Flexible Scalability to Implement Sigmoid and Tanh Functions”, <em>Circuits and Systems (ISCAS) 2020 IEEE International Symposium on</em>, pp. 1-5, 2020.</p>
<h2 id="Title-14"><a href="#Title-14" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-14"><a href="#Authors-14" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-14"><a href="#Abstract-14" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-14"><a href="#Keywords-Index-Terms-14" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-14"><a href="#Comments-14" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-15"><a href="#References-15" class="headerlink" title="References"></a>References</h2><h1 id="Paper13"><a href="#Paper13" class="headerlink" title="Paper13"></a>Paper13</h1><h2 id="Published-in-15"><a href="#Published-in-15" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Yue Gao, Weiqiang Liu, Fabrizio Lombardi, “Design and Implementation of an Approximate Softmax Layer for Deep Neural Networks”, <em>Circuits and Systems (ISCAS) 2020 IEEE International Symposium on</em>, pp. 1-5, 2020.</p>
<h2 id="Title-15"><a href="#Title-15" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-15"><a href="#Authors-15" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-15"><a href="#Abstract-15" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-15"><a href="#Keywords-Index-Terms-15" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-15"><a href="#Comments-15" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-16"><a href="#References-16" class="headerlink" title="References"></a>References</h2><h1 id="Paper12-1109"><a href="#Paper12-1109" class="headerlink" title="Paper12-1109"></a>Paper12-1109</h1><h2 id="Published-in-16"><a href="#Published-in-16" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>T.K.R Arvind, Marcel Brand, Christian Heidorn, Srinivas Boppu, Frank Hannig, Jürgen Teich, “Hardware Implementation of Hyperbolic Tangent Activation Function for Floating Point Formats”, <em>VLSI Design and Test (VDAT) 2020 24th International Symposium on</em>, pp. 1-6, 2020.</p>
<h2 id="Title-16"><a href="#Title-16" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-16"><a href="#Authors-16" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-16"><a href="#Abstract-16" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-16"><a href="#Keywords-Index-Terms-16" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-16"><a href="#Comments-16" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-17"><a href="#References-17" class="headerlink" title="References"></a>References</h2><h1 id="Paper11"><a href="#Paper11" class="headerlink" title="Paper11"></a>Paper11</h1><h2 id="Published-in-17"><a href="#Published-in-17" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Tao Yang, Yadong Wei, Zhijun Tu, Haolun Zeng, Michel A. Kinsy, Nanning Zheng, Pengju Ren, “Design Space Exploration of Neural Network Activation Function Circuits”, <em>Computer-Aided Design of Integrated Circuits and Systems IEEE Transactions on</em>, vol. 38, no. 10, pp. 1974-1978, 2019.</p>
<h2 id="Title-17"><a href="#Title-17" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-17"><a href="#Authors-17" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-17"><a href="#Abstract-17" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-17"><a href="#Keywords-Index-Terms-17" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-17"><a href="#Comments-17" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-18"><a href="#References-18" class="headerlink" title="References"></a>References</h2><h1 id="Paper10"><a href="#Paper10" class="headerlink" title="Paper10"></a>Paper10</h1><h2 id="Published-in-18"><a href="#Published-in-18" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Leandro D. Medus, Taras Iakymchuk, Jose Vicente Frances-Villora, Manuel Bataller-Mompeán, Alfredo Rosado-Muñoz, “A Novel Systolic Parallel Hardware Architecture for the FPGA Acceleration of Feedforward Neural Networks”, <em>Access IEEE</em>, vol. 7, pp. 76084-76103, 2019.</p>
<h2 id="Title-18"><a href="#Title-18" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-18"><a href="#Authors-18" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-18"><a href="#Abstract-18" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-18"><a href="#Keywords-Index-Terms-18" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-18"><a href="#Comments-18" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-19"><a href="#References-19" class="headerlink" title="References"></a>References</h2><h1 id="Paper9"><a href="#Paper9" class="headerlink" title="Paper9"></a>Paper9</h1><h2 id="Published-in-19"><a href="#Published-in-19" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Renato J. Cintra, Stefan Duffner, Christophe Garcia, André Leite, “Low-Complexity Approximate Convolutional Neural Networks”, <em>Neural Networks and Learning Systems IEEE Transactions on</em>, vol. 29, no. 12, pp. 5981-5992, 2018.</p>
<h2 id="Title-19"><a href="#Title-19" class="headerlink" title="Title"></a>Title</h2><h2 id="Authors-19"><a href="#Authors-19" class="headerlink" title="Authors"></a>Authors</h2><h2 id="Abstract-19"><a href="#Abstract-19" class="headerlink" title="Abstract"></a>Abstract</h2><h2 id="Keywords-Index-Terms-19"><a href="#Keywords-Index-Terms-19" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><h2 id="Comments-19"><a href="#Comments-19" class="headerlink" title="Comments"></a>Comments</h2><h2 id="References-20"><a href="#References-20" class="headerlink" title="References"></a>References</h2><h1 id="Paper8-1108"><a href="#Paper8-1108" class="headerlink" title="Paper8-1108"></a>Paper8-1108</h1><h2 id="Published-in-20"><a href="#Published-in-20" class="headerlink" title="Published in"></a>Published in</h2><p><a target="_blank" rel="noopener" href="https://academic.oup.com/nar">Nucleic Acids Research</a> [Oxford Academic]</p>
<p>Volume 46, Issue 6, 6 April 2018, Page e33,</p>
<h2 id="Title-20"><a href="#Title-20" class="headerlink" title="Title"></a>Title</h2><p><a target="_blank" rel="noopener" href="https://academic.oup.com/nar/article/46/6/e33/4791133?login=true">HipMCL: a high-performance parallel implementation of the Markov clustering algorithm for large-scale networks - FREE</a></p>
<p>HipMCL：大规模网络马尔可夫聚类算法的高性能并行实现 - 免费</p>
<h2 id="Authors-20"><a href="#Authors-20" class="headerlink" title="Authors"></a>Authors</h2><p>Ariful Azad, Computational Research Division, Lawrence Berkeley National Laboratory, 1 Cyclotron Road, Berkeley, CA 94720-8150, USA 劳伦斯伯克利国家实验室计算研究部</p>
<p>Georgios A Pavlopoulos, DOE Joint Genome Institute, Lawrence Berkeley National Laboratory, 2800 Mitchell Drive, Walnut Creek, CA 94598, USA 美国能源部联合基因组研究所，劳伦斯伯克利国家实验室</p>
<p>Christos A Ouzounis, Biological Computation &amp; Process Laboratory, Chemical Process &amp; Energy Resources Institute, Centre for Research &amp; Technology Hellas, Thessalonica 57001, Greece 生物计算与过程实验室，化学过程与能源研究所，希腊研究与技术中心，希腊塞萨洛尼卡</p>
<p>Nikos C Kyrpides, DOE Joint Genome Institute, Lawrence Berkeley National Laboratory, 2800 Mitchell Drive, Walnut Creek, CA 94598, USA 美国能源部联合基因组研究所，劳伦斯伯克利国家实验室</p>
<p>Aydin Buluç, Computational Research Division, Lawrence Berkeley National Laboratory, 1 Cyclotron Road, Berkeley, CA 94720-8150, USA and Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA 94720, USA 劳伦斯伯克利国家实验室计算研究部；加州大学伯克利分校电气工程与计算机科学系</p>
<h2 id="Abstract-20"><a href="#Abstract-20" class="headerlink" title="Abstract"></a>Abstract</h2><p>Biological networks capture structural or functional properties of relevant entities such as molecules, proteins or genes. Characteristic examples are gene expression networks or protein–protein interaction networks, which hold information about functional affinities or structural similarities. Such networks have been expanding in size due to increasing scale and abundance of biological data. While various clustering algorithms have been proposed to find highly connected regions, Markov Clustering (MCL) has been one of the most successful approaches to cluster sequence similarity or expression networks. Despite its popularity, MCL’s scalability to cluster large datasets still remains a bottleneck due to high running times and memory demands. Here, we present High-performance MCL (HipMCL), a parallel implementation of the original MCL algorithm that can run on distributed-memory computers. We show that HipMCL can efficiently utilize 2000 compute nodes and cluster a network of ∼70 million nodes with ∼68 billion edges in ∼2.4 h. By exploiting distributed-memory environments, HipMCL clusters large-scale networks several orders of magnitude faster than MCL and enables clustering of even bigger networks. HipMCL is based on MPI and OpenMP and is freely available under a modified BSD license.</p>
<p>生物网络捕获相关实体（例如分子、蛋白质或基因）的结构或功能特性。典型的例子是基因表达网络或蛋白质-蛋白质相互作用网络，它们保存有关功能亲和力或结构相似性的信息。由于生物数据的规模和丰富性不断增加，此类网络的规模一直在扩大。虽然已经提出了各种聚类算法来寻找高度连接的区域，但马尔可夫聚类 (MCL) 一直是对序列相似性或表达网络进行聚类的最成功的方法之一。尽管它很受欢迎，但由于高运行时间和内存需求，<strong>MCL 对大型数据集进行集群的可扩展性仍然是一个瓶颈</strong>。在这里，我们展示了高性能 MCL (HipMCL)，它是原始 MCL 算法的并行实现，可以在分布式内存计算机上运行。我们表明 HipMCL 可以有效地利用 2000 个计算节点，并在 2.4 小时内将一个由 7000 万个节点和 680 亿条边组成的网络聚集在一起。通过利用分布式内存环境，HipMCL 对大规模网络的集群比 MCL 快几个数量级，并支持对更大网络的集群。 HipMCL 基于 MPI 和 OpenMP，<a target="_blank" rel="noopener" href="https://bitbucket.org/azadcse/hipmcl/">可在修改后的 BSD 许可下免费获得</a>。</p>
<h2 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h2><p>No keywords</p>
<h2 id="Comments-20"><a href="#Comments-20" class="headerlink" title="Comments"></a>Comments</h2><p>“By exploiting distributed-memory environments, <a target="_blank" rel="noopener" href="https://bitbucket.org/azadcse/hipmcl/">HipMCL</a> clusters large-scale networks <strong>several orders of magnitude faster</strong> than MCL and enables clustering of even bigger networks. “</p>
<p>“震惊地望着虚空上的残影。<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/萧炎">萧炎</a>半晌无语，他没想到。<a target="_blank" rel="noopener" href="https://bitbucket.org/azadcse/hipmcl/">HipMCL</a>的速度，竟然恐怖如斯。”</p>
<hr>
<h1 id="Paper7-1107"><a href="#Paper7-1107" class="headerlink" title="Paper7-1107"></a>Paper7-1107</h1><h2 id="Published-in-21"><a href="#Published-in-21" class="headerlink" title="Published in"></a>Published in</h2><p><a target="_blank" rel="noopener" href="https://journals.sagepub.com/home/hpc">The International Journal of High Performance Computing Applications</a></p>
<h2 id="Title-21"><a href="#Title-21" class="headerlink" title="Title"></a>Title</h2><p><a target="_blank" rel="noopener" href="https://journals.sagepub.com/doi/abs/10.1177/1094342011403516">The Combinatorial BLAS: design, implementation, and applications</a></p>
<p><a target="_blank" rel="noopener" href="http://nidhogg.cs.ucsb.edu/research/tech_reports/reports/2010-18.pdf">Download</a></p>
<h2 id="Authors-21"><a href="#Authors-21" class="headerlink" title="Authors"></a>Authors</h2><p>Aydın Buluc: High Performance Computing Research Lawrence Berkeley National Laboratory</p>
<p>高性能计算研究劳伦斯伯克利国家实验室</p>
<p> 1 Cyclotron Road, Berkeley, CA 94720 abuluc@lbl.gov</p>
<p>John R. Gilbert: Department of Computer Science University of California, Santa Barbara </p>
<p>加州大学圣巴巴拉分校计算机科学系</p>
<p>Santa Barbara, CA 93106-5110 gilbert@cs.ucsb.edu</p>
<h2 id="Abstract-21"><a href="#Abstract-21" class="headerlink" title="Abstract"></a>Abstract</h2><p>This paper presents a scalable high-performance software library to be used for graph analysis and data mining. Large combinatorial graphs appear in many applications of high-performance computing, including computational biology, informatics, analytics, web search, dynamical systems, and sparse matrix methods. Graph computations are difficult to parallelize using traditional approaches due to their irregular nature and low operational intensity. Many graph computations, however, contain sufficient coarse-grained parallelism for thousands of processors, which can be uncovered by using the right primitives. We describe the parallel Combinatorial BLAS, which consists of a small but powerful set of linear algebra primitives specifically targeting graph and data mining applications. We provide an extensible library interface and some guiding principles for future development. The library is evaluated using two important graph algorithms, in terms of both performance and ease-of-use. The scalability and raw performance of the example applications, using the Combinatorial BLAS, are unprecedented on distributed memory clusters.</p>
<p>本文提出了一个<strong>可扩展的</strong>高性能软件库，用于图形分析和数据挖掘。大型组合图出现在高性能计算的许多应用中，包括计算生物学、信息学、分析学、网络搜索、动力系统和稀疏矩阵方法。由于其不规则性和<strong>低操作强度</strong>，图计算难以使用传统方法并行化。然而，许多图计算包含足够的用于数千个处理器的粗粒度并行性，这可以通过使用正确的primitives来发现。我们描述了并行组合 BLAS，它由一组小而强大的线性代数原语(primitives)组成，专门针对图和数据挖掘应用程序。我们提供了一个可扩展的库接口和一些未来发展的指导原则。在性能和易用性方面，该库使用两种重要的图形算法进行评估。使用组合 BLAS 的示例应用程序的可扩展性和原始性能在分布式内存集群上是前所未有的。</p>
<h2 id="Keywords-1"><a href="#Keywords-1" class="headerlink" title="Keywords"></a>Keywords</h2><p>Mathematical Software, Graph Analysis, Software Framework, Sparse Matrices, Combinatorial Scientific Computing.</p>
<p>数学软件、图形分析、软件框架、稀疏矩阵、组合科学计算。</p>
<p><a target="_blank" rel="noopener" href="https://journals.sagepub.com/keyword/Betweenness+Centrality">Betweenness centrality</a>, <a target="_blank" rel="noopener" href="https://journals.sagepub.com/keyword/Combinatorial+BLAS">combinatorial BLAS</a>, <a target="_blank" rel="noopener" href="https://journals.sagepub.com/keyword/Combinatorial+Scientific+Computing">combinatorial scientific computing</a>, <a target="_blank" rel="noopener" href="https://journals.sagepub.com/keyword/Graph+Analysis">graph analysis</a>, <a target="_blank" rel="noopener" href="https://journals.sagepub.com/keyword/Markov+Clustering">Markov clustering</a>, <a target="_blank" rel="noopener" href="https://journals.sagepub.com/keyword/Mathematical+Software">mathematical software</a>, <a target="_blank" rel="noopener" href="https://journals.sagepub.com/keyword/Parallel+Graph+Library">parallel graph library</a>, <a target="_blank" rel="noopener" href="https://journals.sagepub.com/keyword/Software+Framework">software framework</a>, <a target="_blank" rel="noopener" href="https://journals.sagepub.com/keyword/Sparse+Matrices">sparse matrices</a></p>
<p>介数中心性、组合BLAS、组合科学计算、图分析、马尔可夫聚类、数学软件、并行图库、软件框架、稀疏矩阵</p>
<h2 id="Comments-21"><a href="#Comments-21" class="headerlink" title="Comments"></a>Comments</h2><p>看不懂。</p>
<hr>
<h1 id="Paper6-1105"><a href="#Paper6-1105" class="headerlink" title="Paper6-1105"></a>Paper6-1105</h1><h2 id="Published-in-22"><a href="#Published-in-22" class="headerlink" title="Published in"></a>Published in</h2><p><a target="_blank" rel="noopener" href="https://link.springer.com/conference/para">International Workshop on Applied Parallel Computing</a></p>
<p>PARA 2006: <a target="_blank" rel="noopener" href="https://link.springer.com/book/10.1007/978-3-540-75755-9">Applied Parallel Computing. State of the Art in Scientific Computing</a> pp 260-269| <a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/978-3-540-75755-9_32#citeas">Cite as</a></p>
<h2 id="Title-22"><a href="#Title-22" class="headerlink" title="Title"></a>Title</h2><p><a target="_blank" rel="noopener" href="https://link.springer.com/chapter/10.1007/978-3-540-75755-9_32">High-Performance Graph Algorithms from Parallel Sparse Matrices</a> </p>
<p>基于(from?)并行稀疏矩阵的高性能图算法</p>
<h2 id="Authors-22"><a href="#Authors-22" class="headerlink" title="Authors"></a>Authors</h2><p>John R. Gilbert<sup>1</sup>, Steve Reinhardt<sup>2</sup>, and Viral B. Shah<sup>1</sup></p>
<ol>
<li>1.University of California, Dept. of Computer Science, Harold Frank Hall, Santa Barbara, CA 93106USA</li>
<li>2.Silicon Graphics Inc. </li>
</ol>
<h2 id="Abstract-22"><a href="#Abstract-22" class="headerlink" title="Abstract"></a>Abstract</h2><p>Large-scale computation on graphs and other discrete structures is becoming increasingly important in many applications, including computational biology, web search, and knowledge discovery. High-performance combinatorial computing is an infant field, in sharp contrast with numerical scientific computing.</p>
<p>We argue that many of the tools of high-performance numerical computing – in particular, parallel algorithms and data structures for computation with sparse matrices – can form the nucleus of a robust infrastructure for parallel computing on graphs. We demonstrate this with an implementation of a graph analysis benchmark using the sparse matrix infrastructure in Star-P, our parallel dialect of the Matlab programming language.</p>
<p>图和其他离散结构的大规模计算在许多应用中变得越来越重要，包括计算生物学、网络搜索和知识发现。 高性能组合计算是一个新生领域，与数值科学计算形成鲜明对比。</p>
<p>我们认为，许多高性能数值计算工具——特别是用于稀疏矩阵计算的并行算法和数据结构——可以构成图并行计算的强大基础架构的核心。 我们通过使用 Star-P（我们的 Matlab 编程语言的并行语言）中的稀疏矩阵基础结构实现图分析基准来证明这一点。</p>
<h2 id="Keywords-Index-Terms-20"><a href="#Keywords-Index-Terms-20" class="headerlink" title="Keywords / Index Terms"></a>Keywords / Index Terms</h2><p>Sparse Matrix, Input Graph, Large Graph, Sparse Matrice, Basic Design Principle</p>
<h2 id="Comments-22"><a href="#Comments-22" class="headerlink" title="Comments"></a>Comments</h2><p>被<a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S016781911930136X">Performance optimization, modeling and analysis of sparse matrix-matrix products on multi-core and many-core processors</a>引用。</p>
<hr>
<h1 id="Paper5-1104"><a href="#Paper5-1104" class="headerlink" title="Paper5-1104"></a>Paper5-1104</h1><h2 id="Published-in-23"><a href="#Published-in-23" class="headerlink" title="Published in"></a>Published in</h2><p><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/journal/parallel-computing">Parallel Computing</a></p>
<h2 id="Title-23"><a href="#Title-23" class="headerlink" title="Title"></a>Title</h2><p><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S016781911930136X">Performance optimization, modeling and analysis of sparse matrix-matrix products on multi-core and many-core processors</a></p>
<p>稀疏矩阵乘法在多核和众核处理器上的性能优化、建模与分析</p>
<h2 id="Authors-23"><a href="#Authors-23" class="headerlink" title="Authors"></a>Authors</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S016781911930136X#!">Yusuke Nagasaka</a>: Tokyo Institute of Technology, Tokyo, Japan【长坂雄介？，东京工业大学】</li>
<li><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S016781911930136X#!">Satoshi Matsuoka</a>: RIKEN Center for Computational Science, Kobe, Japan【松冈聪？，RIKEN 计算科学中心，日本神户】</li>
<li><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S016781911930136X#!">Ariful Azad</a>: Indiana University, Bloomington, Indiana, USA【阿里夫·阿扎德，印第安纳大学，布卢明顿，印第安纳州，美国】 </li>
<li><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S016781911930136X#!">Aydın Buluç</a>: Lawrence Berkeley National Laboratory, Berkeley, California, USA【艾登布卢奇，劳伦斯伯克利国家实验室，美国加利福尼亚州伯克利】</li>
</ul>
<h2 id="Abstract-23"><a href="#Abstract-23" class="headerlink" title="Abstract"></a>Abstract</h2><p>Sparse matrix-matrix multiplication (SpGEMM) is a computational primitive that is widely used in areas ranging from traditional <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/engineering/numerical-application">numerical applications</a> to recent <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/computer-science/big-data-analysis">big data analysis</a> and <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/computer-science/machine-learning">machine learning</a>. Although many SpGEMM algorithms have been proposed, hardware specific optimizations for multi- and many-core processors are lacking and a detailed analysis of their performance under various use cases and matrices is not available. We firstly identify and mitigate multiple bottlenecks with <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/computer-science/memory-management">memory management</a> and thread scheduling on <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/computer-science/intel-xeon-phi">Intel Xeon Phi</a> (Knights Landing or KNL). <strong>Specifically targeting many-core processors</strong>, we develop a hash-table-based algorithm and optimize a heap-based shared-memory SpGEMM algorithm. We examine their performance together with other publicly available codes. Different from the literature, our evaluation also includes use cases that are representative of real <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/computer-science/graph-algorithms">graph algorithms</a>, such as multi-source breadth-first search or triangle counting. <strong>Our hash-table and heap-based algorithms are showing significant speedups from libraries in the majority of the cases</strong> while different algorithms dominate the other scenarios with different matrix size, <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/computer-science/sparsity">sparsity</a>, compression factor and operation type. We wrap up in-depth evaluation results and make a recipe to give the best SpGEMM algorithm for target scenario. We build the performance model for hash-table and heap-based algorithms, which supports the recipe. A critical finding is that hash-table-based SpGEMM gets a significant performance boost if the nonzeros are not required to be sorted within each row of the output matrix. Finally, we integrate our implementations into a large-scale protein clustering code named HipMCL, accelerating its SpGEMM kernel by up to 10X and achieving an overall performance boost for the whole HipMCL application by 2.6X.</p>
<p>稀疏矩阵-矩阵乘法 (SpGEMM) 是一种计算原语（computational primitive），广泛应用于从传统<a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/engineering/numeric-application">数值应用</a> 到最近的<a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/computer-science/big-data-analysis">大数据分析</a>和<a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/computer-science/machine-learning">机器学习</a>.尽管已经提出了许多 SpGEMM 算法，但缺乏针对多核和众核处理器的硬件特定优化，并且没有对其在各种测试样例下的性能进行详细分析。我们首先通过<a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/computer-science/memory-management">内存管理</a>和<a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/computer-science/intel-xeon-phi">Intel Xeon Phi</a>上的线程调度来识别和缓解多个瓶颈（Knights Landing 或 KNL）。<strong>我们专门针对众核处理器</strong>，开发了基于哈希表的算法并优化了基于堆的共享内存 SpGEMM 算法。我们与其他公开的代码一起检查其性能。与文献不同，我们的评估还包括代表真实<a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/computer-science/graph-algorithms">图算法</a>的用例，例如多源广度优先搜索或三角形计数。在大多数库中，我们的哈希表和基于堆的算法在可以显著加速，而不同的算法主导了具有不同矩阵大小，<a target="_blank" rel="noopener" href="https://www.sciencedirect.com/topics/computer -science/sparsity">稀疏程度</a>、压缩因子和操作类型的其他场景（？）。我们总结了深入的评估结果并制定了一个方法，为目标场景提供最佳 SpGEMM 算法。我们为支持这个方法的哈希表和基于堆的算法构建了性能模型。一个重要的发现是，如果不需要在输出矩阵的每一行内对非零值进行排序，那么基于哈希表的 SpGEMM 将获得显着的性能提升。最后，我们将我们的实现集成到一个名为 HipMCL 的大规模蛋白质聚类代码中，将其 SpGEMM 内核的速度提高了 10 倍，并将整个 HipMCL 应用程序的整体性能提高了 2.6 倍。</p>
<h2 id="Keywords-2"><a href="#Keywords-2" class="headerlink" title="Keywords"></a>Keywords</h2><p>Sparse matrix</p>
<p>SpGEMM</p>
<p>Intel KNL</p>
<h2 id="Comments-23"><a href="#Comments-23" class="headerlink" title="Comments"></a>Comments</h2><p>需要好好看。</p>
<p>简而言之，multi-core是多核，many-core是众核。</p>
<p><img src="/2021/10/29/papers/1.png" alt="cores"></p>
<hr>
<h1 id="Paper4-1106"><a href="#Paper4-1106" class="headerlink" title="Paper4-1106"></a>Paper4-1106</h1><h2 id="Published-in-24"><a href="#Published-in-24" class="headerlink" title="Published in"></a>Published in</h2><p>cite <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/537127/citations?tabFilter=papers#citations">Sigmoid generators for neural computing using piecewise approximations</a></p>
<p>Ahmed M. Abdelsalam, J. M. Pierre Langlois, F. Cheriet, “A Configurable FPGA Implementation of the Tanh Function Using DCT Interpolation”, <em>Field-Programmable Custom Computing Machines (FCCM) 2017 IEEE 25th Annual International Symposium on</em>, pp. 168-171, 2017.</p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/xpl/conhome/7964000/proceeding">2017 IEEE 25th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)</a></p>
<h2 id="Title-24"><a href="#Title-24" class="headerlink" title="Title"></a>Title</h2><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/7966673">A Configurable FPGA Implementation of the Tanh Function Using DCT Interpolation</a></p>
<h2 id="Authors-24"><a href="#Authors-24" class="headerlink" title="Authors"></a>Authors</h2><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/author/37086113448">Ahmed M. Abdelsalam</a></p>
<p>Computer and Software Engineering Department, Polytechnique Montreal, Montreal, Canada</p>
<p>加拿大蒙特利尔理工学院计算机与软件工程系</p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/author/37276914800">J. M. Pierre Langlois</a></p>
<p>Computer and Software Engineering Department, Polytechnique Montreal, Montreal, Canada</p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/author/37284363700">F. Cheriet</a></p>
<p>Computer and Software Engineering Department, Polytechnique Montreal, Montreal, Canada</p>
<h2 id="Abstract-24"><a href="#Abstract-24" class="headerlink" title="Abstract"></a>Abstract</h2><p>Efficient implementation of non-linear activation functions is essential to the implementation of deep learning models on FPGAs. We introduce such an implementation based on the Discrete Cosine Transform Interpolation Filter (DCTIF). The proposed interpolation architecture combines simple arithmetic operations on the stored samples of the hyperbolic tangent function and on input data. It achieves almost 3× better precision than previous works while using a similar amount computational resources and a small amount of memory. Various combinations of DCTIF parameters can be chosen to trade off the accuracy and the overall circuit complexity of the tanh function. In one case, the proposed architecture approximates the hyperbolic tangent activation function with 0.004 maximum error while requiring only 1.45 kbits BRAM memory and 21 LUTs of a Virtex-7 FPGA.</p>
<p>非线性激活函数的有效实现对于在 FPGA 上实现深度学习模型至关重要。 我们介绍了基于<strong>离散余弦变换插值滤波器 (DCTIF) 的这种实现</strong>。 所提出的插值架构结合了对双曲正切函数的存储样本和输入数据的简单算术运算。 在使用类似数量的计算资源和少量内存的情况下，它的精度比以前的工作高出近 3 倍。 可以选择 DCTIF 参数的各种组合来权衡 tanh 函数的准确性和整体电路复杂性。 在一种情况下，所提出的架构以 0.004 的最大误差逼近双曲正切激活函数，同时仅需要 1.45 kbits BRAM 存储器和 Virtex-7 FPGA 的 21 个 LUT。</p>
<h2 id="Keywords-3"><a href="#Keywords-3" class="headerlink" title="Keywords"></a>Keywords</h2><ul>
<li>IEEE Keywords <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:Interpolation&amp;newsearch=true">Interpolation</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:Field programmable gate arrays&amp;newsearch=true">Field programmable gate arrays</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:Table lookup&amp;newsearch=true">Table lookup</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:Discrete cosine transforms&amp;newsearch=true">Discrete cosine transforms</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:Decoding&amp;newsearch=true">Decoding</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:Hardware&amp;newsearch=true">Hardware</a></li>
<li>INSPEC: Controlled Indexing <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:circuit complexity&amp;newsearch=true">circuit complexity</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:discrete cosine transforms&amp;newsearch=true">discrete cosine transforms</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:field programmable gate arrays&amp;newsearch=true">field programmable gate arrays</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:interpolation&amp;newsearch=true">interpolation</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:learning .LB.artificial intelligence.RB.&amp;newsearch=true">learning (artificial intelligence)</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:transfer functions&amp;newsearch=true">transfer functions</a></li>
<li>INSPEC: Non-Controlled Indexing <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:configurable FPGA implementation&amp;newsearch=true">configurable FPGA implementation</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:tanh function&amp;newsearch=true">tanh function</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:nonlinear activation functions&amp;newsearch=true">nonlinear activation functions</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:deep learning models&amp;newsearch=true">deep learning models</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:discrete cosine transform interpolation filter&amp;newsearch=true">discrete cosine transform interpolation filter</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:DCTIF&amp;newsearch=true">DCTIF</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:circuit complexity&amp;newsearch=true">circuit complexity</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:BRAM memory&amp;newsearch=true">BRAM memory</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:LUT&amp;newsearch=true">LUT</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:Virtex-7 FPGA&amp;newsearch=true">Virtex-7 FPGA</a></li>
<li>Author Keywords <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:Deep Neural Network .LB.DNN.RB.&amp;newsearch=true">Deep Neural Network (DNN)</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:Embedded FPGA&amp;newsearch=true">Embedded FPGA</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:Deep learning&amp;newsearch=true">Deep learning</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:Activation function&amp;newsearch=true">Activation function</a>, <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/search/searchresult.jsp?matchBoolean=true&amp;queryText=&quot;Index Terms&quot;:Hyperbolic tangent&amp;newsearch=true">Hyperbolic tangent</a></li>
</ul>
<h2 id="Comments-24"><a href="#Comments-24" class="headerlink" title="Comments"></a>Comments</h2><p>方法不同。</p>
<p>从Abstract可以看出来作者好像也很难权衡参数到底怎么配。和我挺像的。。。</p>
<hr>
<h1 id="paper3-1103"><a href="#paper3-1103" class="headerlink" title="paper3-1103"></a>paper3-1103</h1><h2 id="Published-in-25"><a href="#Published-in-25" class="headerlink" title="Published in"></a>Published in</h2><p>TCAS-I</p>
<p>IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS—I: REGULAR PAPERS, VOL. 68, NO. 8, AUGUST 2021</p>
<h2 id="Title-25"><a href="#Title-25" class="headerlink" title="Title"></a>Title</h2><p>Low-Complexity High-Precision Method and Architecture for Computing the Logarithm of Complex Numbers</p>
<h2 id="Authors-25"><a href="#Authors-25" class="headerlink" title="Authors"></a>Authors</h2><p>Hui Chen , Graduate Student Member, IEEE, Zongguang Yu , Zhonghai Lu , Senior Member, IEEE, Yuxiang Fu , Member, IEEE, and Li Li , Member, IEEE</p>
<p>Hui Chen, Zongguang Yu, Yonggang Zhang, Yuxiang Fu, and Li Li are with the School of Electronic Science and Engineering, Nanjing University, Nanjing 210093, China (e-mail: yuxiangfu@nju.edu.cn; lili@nju.edu.cn).</p>
<p>Zhonghai Lu is with the Department of Electrical Engineering, School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, 16440 Stockholm, Sweden.</p>
<h2 id="Abstract-25"><a href="#Abstract-25" class="headerlink" title="Abstract"></a>Abstract</h2><p>This paper proposes a low-complexity method and architecture to compute the logarithm of complex numbers based on coordinate rotation digital computer (CORDIC). Our method takes advantage of the vector mode of circular CORDIC and hyperbolic CORDIC, which only needs shift-add operations in its hardware implementation. Our architecture has lower design complexity and higher performance compared with conventional architectures. Through software simulation, we show that this method can achieve high precision for logarithm computation, reaching the relative error of  $10^{−7}$. Finally, we design and implementation example circuit under TSMC 28nm CMOS technology. According to the synthesis report, our architecture has smaller area, lower power consumption, higher precision and wider operation range compared with the alternative architectures.</p>
<p>本文提出了一种基于CORDIC方法计算复数对数的低复杂度方法和架构。我们的方法利用了循环 CORDIC 和双曲线 CORDIC 的矢量模式的长处，在硬件实现中只需进行移位和加法运算。与传统架构相比，我们的架构具有更低的设计复杂性和更高的性能。通过软件仿真，我们表明该方法可以实现对数计算的高精度，达到$10^{−7}$的<strong>相对误差</strong>。 最后，我们在TSMC 28nm CMOS技术下设计并实现了一个示例电路。根据综合报告，我们的架构与替代架构相比具有更小的面积、更低的功耗、更高的精度和更宽的操作范围。</p>
<h2 id="Comments-25"><a href="#Comments-25" class="headerlink" title="Comments"></a>Comments</h2><p>他们的相对误差非常低，但是最大绝对误差是多少？</p>
<hr>
<h1 id="paper2-1102"><a href="#paper2-1102" class="headerlink" title="paper2-1102"></a>paper2-1102</h1><h2 id="Published-in-26"><a href="#Published-in-26" class="headerlink" title="Published in"></a>Published in</h2><p>TCAS-I</p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8919">IEEE Transactions on Circuits and Systems I: Regular Papers</a> ( Early Access )</p>
<p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9585319">Paper LINK</a></p>
<h2 id="Title-26"><a href="#Title-26" class="headerlink" title="Title"></a>Title</h2><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/9585319">Memory-Efficient CNN Accelerator Based on Interlayer Feature Map Compression</a></p>
<h2 id="Authors-26"><a href="#Authors-26" class="headerlink" title="Authors"></a>Authors</h2><p>Zhuang Shao; Xiaoliang Chen; Li Du; Lei Chen; Yuan Du; Wei Zhuang; Huadong Wei; Chenjia Xie; Zhongfeng Wang</p>
<h2 id="Abstract-26"><a href="#Abstract-26" class="headerlink" title="Abstract"></a>Abstract</h2><p>Existing deep convolutional neural networks (CNNs) generate massive interlayer feature data during network inference. To maintain real-time processing in embedded systems, large on-chip memory is required to buffer the interlayer feature maps. In this paper, we propose an efficient hardware accelerator with an interlayer feature compression technique to significantly reduce the required on-chip memory size and off-chip memory access bandwidth. The accelerator compresses interlayer feature maps through transforming the stored data into frequency domain using hardware-implemented 8×8 discrete cosine transform (DCT). The high-frequency components are removed after the DCT through quantization. Sparse matrix compression is utilized to further compress the interlayer feature maps. The on-chip memory allocation scheme is designed to support dynamic configuration of the feature map buffer size and scratch pad size according to different network-layer requirements. The hardware accelerator combines compression, decompression, and CNN acceleration into one computing stream, achieving minimal compressing and processing delay. A prototype accelerator is implemented on an FPGA platform and also synthesized in TSMC 28-nm COMS technology. It achieves 403GOPS peak throughput and 1.4× 3.3× interlayer feature map reduction by adding light hardware area overhead, making it a promising hardware accelerator for intelligent IoT devices.</p>
<p>现有的深度卷积神经网络 (CNN) 在网络推理过程中会生成大量的层间特征数据。为了在嵌入式系统中保持实时处理，需要大量的片上存储器来缓冲层间特征图。在本文中，我们提出了一种具有层间特征压缩技术的高效硬件加速器，以显着减少所需的片上内存大小和片外内存访问带宽。加速器通过使用硬件实现的 8×8 离散余弦变换 (DCT) 将存储的数据转换到频域来压缩层间特征图。高频分量在 DCT 之后通过量化被去除。稀疏矩阵压缩用于进一步压缩层间特征图。片上内存分配方案旨在支持根据不同网络层要求动态配置特征图buffer大小和scratch pad大小。硬件加速器将压缩、解压和CNN加速整合到一个计算流中，实现最小的压缩和处理延迟。原型加速器在 FPGA 平台上实现，并在 TSMC 28-nm COMS 技术中综合。它通过增加很少的硬件区域开销实现了 403GOPS 峰值吞吐量和 1.4×3.3× 层间特征图减少，使其成为智能物联网设备的有前途的硬件加速器。</p>
<h2 id="Index-Terms"><a href="#Index-Terms" class="headerlink" title="Index Terms"></a>Index Terms</h2><p>Deep convolution neural networks, discrete cosine transform, quantization, interlayer feature maps compression.</p>
<p>深度卷积神经网络、离散余弦变换、量化、层间特征图压缩。</p>
<h2 id="Comments-26"><a href="#Comments-26" class="headerlink" title="Comments"></a>Comments</h2><p>iscl的第一篇TCAS-I。</p>
<hr>
<h1 id="paper1-1101"><a href="#paper1-1101" class="headerlink" title="paper1-1101"></a>paper1-1101</h1><h2 id="Published-in-27"><a href="#Published-in-27" class="headerlink" title="Published in"></a>Published in</h2><p>TVLSI。</p>
<p>IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS, VOL. 29, NO. 7, JULY 2021</p>
<h2 id="Title-27"><a href="#Title-27" class="headerlink" title="Title"></a>Title</h2><p>PWL-Based Architecture for the Logarithmic Computation of Floating-Point Numbers</p>
<h2 id="Authors-27"><a href="#Authors-27" class="headerlink" title="Authors"></a>Authors</h2><p>Fei Lyu , Zhelong Mao , Jin Zhang, Yu Wang, and Yuanyong Luo</p>
<p>Fei Lyu and Jin Zhang are with the School of Electronics and Information Engineering, Jinling Institute of Technology, Nanjing 211169, China.</p>
<p>Zhelong Mao and Yu Wang are with the School of Electronics Engineering, Nanjing Xiaozhuang University, Nanjing 211171, China.</p>
<p>Yuanyong Luo is with the Linx Laboratory, <strong>Department of Turing Architecture Design, HiSilicon, Huawei Corporation, </strong>Shenzhen 518129, China.</p>
<h2 id="Abstract-27"><a href="#Abstract-27" class="headerlink" title="Abstract"></a>Abstract</h2><p>In this brief, we propose a logarithmic converter for floating-point numbers based on the piecewise linear (PWL) approximation method. The proposed method is applicable to any customized floating-point format with a mantissa length of 16–23 bits and a maximum absolute error (MAE) larger than $10^{−6}$. The logarithmic function is automatically segmented into several maximal subsections by a software-based segmentation scheme with the restriction of a predefined MAE and a fractional word length for the computing units. Then, we make a tradeoff between the piecewise number and the fractional word length. Based on the results of the segmentor, our design is coded in the Verilog hardware description language. The synthesized results show that our design consumes less area, time, and power without compromising accuracy compared to existing techniques based on the COordinate Rotation Digital Computer (CORDIC) and PWL methods.</p>
<p>在这篇brief中，我们提出了一种基于分段线性 (PWL) 拟合方法的浮点对数转换器。 所提出的方法适用于尾数长度为 16-23 位且最大绝对误差 (MAE) 大于 10-6 的任何自定义浮点格式。 目标拟合对数函数通过软件分段器根据预定义的MAE和小数位数限制自动分成多段。 而后我们在分段数和小数字长之间进行权衡。 基于分段器的输出，我们用Verilog完成了硬件实现。 综合结果表明，与基于CORDIC方法和和 PWL 方法的现有技术相比，我们的设计在不影响精度的情况下具有更低的面积、时延和功耗。</p>
<h2 id="Index-Terms-1"><a href="#Index-Terms-1" class="headerlink" title="Index Terms"></a>Index Terms</h2><p>Logarithmic converter, maximum absolute error (MAE), piecewise linear (PWL) approximation.</p>
<p>对数转换器、最大绝对误差 (MAE)、分段线性 (PWL) 拟合。</p>
<h2 id="Comments-27"><a href="#Comments-27" class="headerlink" title="Comments"></a>Comments</h2><p>5页短文，可以用于学习如何写短paper。</p>
<hr>
<p><img src="/2021/10/29/papers/qiufen.jpg" alt="QiuFen"></p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Haoran Geng
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://njughr.github.io/2021/10/29/papers/" title="Pipes">https://njughr.github.io/2021/10/29/papers/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/ic/" rel="tag"># ic</a>
              <a href="/tags/cs/" rel="tag"># cs</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/10/26/hdl/" rel="prev" title="hdl学习">
      <i class="fa fa-chevron-left"></i> hdl学习
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/10/31/english/" rel="next" title="English Learning">
      English Learning <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%98%85%E8%AF%BB%E6%96%B9%E6%B3%95"><span class="nav-number">1.</span> <span class="nav-text">阅读方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93"><span class="nav-number">1.1.</span> <span class="nav-text">要点总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-number">1.2.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Template"><span class="nav-number">2.</span> <span class="nav-text">Template</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in"><span class="nav-number">2.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title"><span class="nav-number">2.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors"><span class="nav-number">2.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract"><span class="nav-number">2.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms"><span class="nav-number">2.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments"><span class="nav-number">2.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-1"><span class="nav-number">2.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper27"><span class="nav-number">3.</span> <span class="nav-text">Paper27</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-1"><span class="nav-number">3.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-1"><span class="nav-number">3.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-1"><span class="nav-number">3.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-1"><span class="nav-number">3.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-1"><span class="nav-number">3.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-1"><span class="nav-number">3.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-2"><span class="nav-number">3.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper26"><span class="nav-number">4.</span> <span class="nav-text">Paper26</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-2"><span class="nav-number">4.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-2"><span class="nav-number">4.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-2"><span class="nav-number">4.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-2"><span class="nav-number">4.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-2"><span class="nav-number">4.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-2"><span class="nav-number">4.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-3"><span class="nav-number">4.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper25"><span class="nav-number">5.</span> <span class="nav-text">Paper25</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-3"><span class="nav-number">5.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-3"><span class="nav-number">5.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-3"><span class="nav-number">5.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-3"><span class="nav-number">5.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-3"><span class="nav-number">5.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-3"><span class="nav-number">5.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-4"><span class="nav-number">5.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper24-1110"><span class="nav-number">6.</span> <span class="nav-text">Paper24-1110</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-4"><span class="nav-number">6.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-4"><span class="nav-number">6.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-4"><span class="nav-number">6.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-4"><span class="nav-number">6.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-4"><span class="nav-number">6.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-4"><span class="nav-number">6.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-5"><span class="nav-number">6.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper23"><span class="nav-number">7.</span> <span class="nav-text">Paper23</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-5"><span class="nav-number">7.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-5"><span class="nav-number">7.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-5"><span class="nav-number">7.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-5"><span class="nav-number">7.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-5"><span class="nav-number">7.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-5"><span class="nav-number">7.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-6"><span class="nav-number">7.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper22"><span class="nav-number">8.</span> <span class="nav-text">Paper22</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-6"><span class="nav-number">8.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-6"><span class="nav-number">8.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-6"><span class="nav-number">8.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-6"><span class="nav-number">8.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-6"><span class="nav-number">8.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-6"><span class="nav-number">8.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-7"><span class="nav-number">8.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper21"><span class="nav-number">9.</span> <span class="nav-text">Paper21</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-7"><span class="nav-number">9.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-7"><span class="nav-number">9.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-7"><span class="nav-number">9.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-7"><span class="nav-number">9.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-7"><span class="nav-number">9.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-7"><span class="nav-number">9.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-8"><span class="nav-number">9.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper20"><span class="nav-number">10.</span> <span class="nav-text">Paper20</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-8"><span class="nav-number">10.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-8"><span class="nav-number">10.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-8"><span class="nav-number">10.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-8"><span class="nav-number">10.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-8"><span class="nav-number">10.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-8"><span class="nav-number">10.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-9"><span class="nav-number">10.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper19"><span class="nav-number">11.</span> <span class="nav-text">Paper19</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-9"><span class="nav-number">11.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-9"><span class="nav-number">11.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-9"><span class="nav-number">11.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-9"><span class="nav-number">11.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-9"><span class="nav-number">11.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-9"><span class="nav-number">11.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-10"><span class="nav-number">11.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper18"><span class="nav-number">12.</span> <span class="nav-text">Paper18</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-10"><span class="nav-number">12.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-10"><span class="nav-number">12.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-10"><span class="nav-number">12.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-10"><span class="nav-number">12.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-10"><span class="nav-number">12.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-10"><span class="nav-number">12.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-11"><span class="nav-number">12.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper17"><span class="nav-number">13.</span> <span class="nav-text">Paper17</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-11"><span class="nav-number">13.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-11"><span class="nav-number">13.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-11"><span class="nav-number">13.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-11"><span class="nav-number">13.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-11"><span class="nav-number">13.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-11"><span class="nav-number">13.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-12"><span class="nav-number">13.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper16"><span class="nav-number">14.</span> <span class="nav-text">Paper16</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-12"><span class="nav-number">14.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-12"><span class="nav-number">14.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-12"><span class="nav-number">14.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-12"><span class="nav-number">14.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-12"><span class="nav-number">14.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-12"><span class="nav-number">14.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-13"><span class="nav-number">14.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper15"><span class="nav-number">15.</span> <span class="nav-text">Paper15</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-13"><span class="nav-number">15.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-13"><span class="nav-number">15.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-13"><span class="nav-number">15.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-13"><span class="nav-number">15.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-13"><span class="nav-number">15.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-13"><span class="nav-number">15.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-14"><span class="nav-number">15.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper14"><span class="nav-number">16.</span> <span class="nav-text">Paper14</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-14"><span class="nav-number">16.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-14"><span class="nav-number">16.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-14"><span class="nav-number">16.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-14"><span class="nav-number">16.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-14"><span class="nav-number">16.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-14"><span class="nav-number">16.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-15"><span class="nav-number">16.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper13"><span class="nav-number">17.</span> <span class="nav-text">Paper13</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-15"><span class="nav-number">17.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-15"><span class="nav-number">17.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-15"><span class="nav-number">17.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-15"><span class="nav-number">17.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-15"><span class="nav-number">17.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-15"><span class="nav-number">17.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-16"><span class="nav-number">17.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper12-1109"><span class="nav-number">18.</span> <span class="nav-text">Paper12-1109</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-16"><span class="nav-number">18.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-16"><span class="nav-number">18.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-16"><span class="nav-number">18.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-16"><span class="nav-number">18.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-16"><span class="nav-number">18.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-16"><span class="nav-number">18.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-17"><span class="nav-number">18.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper11"><span class="nav-number">19.</span> <span class="nav-text">Paper11</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-17"><span class="nav-number">19.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-17"><span class="nav-number">19.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-17"><span class="nav-number">19.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-17"><span class="nav-number">19.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-17"><span class="nav-number">19.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-17"><span class="nav-number">19.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-18"><span class="nav-number">19.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper10"><span class="nav-number">20.</span> <span class="nav-text">Paper10</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-18"><span class="nav-number">20.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-18"><span class="nav-number">20.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-18"><span class="nav-number">20.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-18"><span class="nav-number">20.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-18"><span class="nav-number">20.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-18"><span class="nav-number">20.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-19"><span class="nav-number">20.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper9"><span class="nav-number">21.</span> <span class="nav-text">Paper9</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-19"><span class="nav-number">21.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-19"><span class="nav-number">21.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-19"><span class="nav-number">21.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-19"><span class="nav-number">21.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-19"><span class="nav-number">21.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-19"><span class="nav-number">21.6.</span> <span class="nav-text">Comments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References-20"><span class="nav-number">21.7.</span> <span class="nav-text">References</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper8-1108"><span class="nav-number">22.</span> <span class="nav-text">Paper8-1108</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-20"><span class="nav-number">22.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-20"><span class="nav-number">22.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-20"><span class="nav-number">22.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-20"><span class="nav-number">22.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords"><span class="nav-number">22.5.</span> <span class="nav-text">Keywords</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-20"><span class="nav-number">22.6.</span> <span class="nav-text">Comments</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper7-1107"><span class="nav-number">23.</span> <span class="nav-text">Paper7-1107</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-21"><span class="nav-number">23.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-21"><span class="nav-number">23.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-21"><span class="nav-number">23.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-21"><span class="nav-number">23.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-1"><span class="nav-number">23.5.</span> <span class="nav-text">Keywords</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-21"><span class="nav-number">23.6.</span> <span class="nav-text">Comments</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper6-1105"><span class="nav-number">24.</span> <span class="nav-text">Paper6-1105</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-22"><span class="nav-number">24.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-22"><span class="nav-number">24.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-22"><span class="nav-number">24.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-22"><span class="nav-number">24.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-Index-Terms-20"><span class="nav-number">24.5.</span> <span class="nav-text">Keywords &#x2F; Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-22"><span class="nav-number">24.6.</span> <span class="nav-text">Comments</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper5-1104"><span class="nav-number">25.</span> <span class="nav-text">Paper5-1104</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-23"><span class="nav-number">25.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-23"><span class="nav-number">25.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-23"><span class="nav-number">25.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-23"><span class="nav-number">25.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-2"><span class="nav-number">25.5.</span> <span class="nav-text">Keywords</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-23"><span class="nav-number">25.6.</span> <span class="nav-text">Comments</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Paper4-1106"><span class="nav-number">26.</span> <span class="nav-text">Paper4-1106</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-24"><span class="nav-number">26.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-24"><span class="nav-number">26.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-24"><span class="nav-number">26.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-24"><span class="nav-number">26.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Keywords-3"><span class="nav-number">26.5.</span> <span class="nav-text">Keywords</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-24"><span class="nav-number">26.6.</span> <span class="nav-text">Comments</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#paper3-1103"><span class="nav-number">27.</span> <span class="nav-text">paper3-1103</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-25"><span class="nav-number">27.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-25"><span class="nav-number">27.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-25"><span class="nav-number">27.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-25"><span class="nav-number">27.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-25"><span class="nav-number">27.5.</span> <span class="nav-text">Comments</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#paper2-1102"><span class="nav-number">28.</span> <span class="nav-text">paper2-1102</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-26"><span class="nav-number">28.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-26"><span class="nav-number">28.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-26"><span class="nav-number">28.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-26"><span class="nav-number">28.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Index-Terms"><span class="nav-number">28.5.</span> <span class="nav-text">Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-26"><span class="nav-number">28.6.</span> <span class="nav-text">Comments</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#paper1-1101"><span class="nav-number">29.</span> <span class="nav-text">paper1-1101</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Published-in-27"><span class="nav-number">29.1.</span> <span class="nav-text">Published in</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Title-27"><span class="nav-number">29.2.</span> <span class="nav-text">Title</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Authors-27"><span class="nav-number">29.3.</span> <span class="nav-text">Authors</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstract-27"><span class="nav-number">29.4.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Index-Terms-1"><span class="nav-number">29.5.</span> <span class="nav-text">Index Terms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Comments-27"><span class="nav-number">29.6.</span> <span class="nav-text">Comments</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Haoran Geng"
      src="/images/paperboat.jpg">
  <p class="site-author-name" itemprop="name">Haoran Geng</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">23</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/njughr" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;njughr" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hrgeng@smail.nju.edu.cn" title="E-Mail → mailto:hrgeng@smail.nju.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=1444528490&auto=0&height=66"></iframe>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Haoran Geng</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script color='105,7,90' opacity='0.6' zIndex='-1' count='100' src="/lib/canvas-nest/canvas-nest-nomobile.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>


  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false});</script></body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>
